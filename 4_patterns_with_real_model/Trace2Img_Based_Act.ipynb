{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45772a44-6a78-4c25-be98-a45a491dc7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import pm4py\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50ab84b-3af9-4dca-b8d7-24f1515f17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем уникальные активити\n",
    "activities = ['Start', 'Ist', 'A', 'B', 'Icmp', 'T', 'End', 'C', 'E', 'D']\n",
    "act_dict = {}\n",
    "\n",
    "# проводим  между номером и активити\n",
    "act_num = len(activities)\n",
    "for i in range(act_num):\n",
    "  act_dict[activities[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43031735-e824-4236-8389-5a89808c5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Converter(ABC):\n",
    "  \n",
    "  def __init__(self, log_file_path, ch_sep, caseID_col_name, act_col_name, ts_col_name):\n",
    "        # Динамические поля (переменные объекта)\n",
    "        self.caseID_col_name = caseID_col_name \n",
    "        self.act_col_name = act_col_name\n",
    "        self.ts_col_name = ts_col_name\n",
    "\n",
    "        #self.event_log = pd.read_csv(log_file_path, sep=ch_sep)\n",
    "        self.event_log = pm4py.read_xes(log_file_path)\n",
    "        self.event_log[caseID_col_name]=self.event_log[caseID_col_name].apply(str)\n",
    "        self.event_log[act_col_name]=self.event_log[act_col_name].apply(str)\n",
    "        #self.event_log[ts_col_name]= pd.to_datetime(self.event_log[ts_col_name])\n",
    "\n",
    "        self.event_log = self.event_log[[act_col_name, caseID_col_name, ts_col_name]]\n",
    "\n",
    "  @abstractmethod\n",
    "  def convert(self):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3912ddcc-43dd-4e33-a6b6-fa543f4b9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityConverter(Converter):\n",
    "\n",
    "  def __get_unique_ids__(self):\n",
    "    ids = list(self.event_log[self.caseID_col_name].unique())\n",
    "    return ids\n",
    "\n",
    "  def __get_case_logs__(self, ids_list):\n",
    "    case_logs = []\n",
    "    for id in ids_list:\n",
    "      case_log = self.event_log.query(\"`{0}` == @id\".format(self.caseID_col_name))\n",
    "      case_log.sort_values(by=[self.ts_col_name])\n",
    "      case_logs.append(case_log)\n",
    "    return case_logs\n",
    "\n",
    "  def __get_prefix_traces__(self):\n",
    "    cases_prefix_traces = []\n",
    "    self.max_len_prefix_trace = 0\n",
    "\n",
    "    for case_log in self.case_logs:\n",
    "      prefix_traces_act = []\n",
    "      for i in range(1, len(case_log)+1):\n",
    "        prifix_trace = case_log[self.act_col_name].values[0:i]\n",
    "\n",
    "        #находим самую длинную префиксную трассу\n",
    "        if (len(prifix_trace) > self.max_len_prefix_trace):\n",
    "          self.max_len_prefix_trace = len(prifix_trace)\n",
    "\n",
    "        prefix_traces_act.append(prifix_trace)\n",
    "\n",
    "      cases_prefix_traces.append(prefix_traces_act)\n",
    "    return cases_prefix_traces\n",
    "\n",
    "  def __get_activity_matrices__(self, act_num, act_dict):\n",
    "    activity_matrices = []\n",
    "    for prefix_traces in self.cases_prefix_traces:\n",
    "      np_matrix = []\n",
    "      matrix = [ [0]*act_num for i in range(self.max_len_prefix_trace)]\n",
    "      for i in range(len(prefix_traces)):\n",
    "        for act in prefix_traces[i]:\n",
    "          act_index = act_dict[act]\n",
    "          matrix[i][act_index] += 1\n",
    "          np_matrix = np.asmatrix(matrix)\n",
    "          np_matrix = np_matrix.astype(\"uint8\")\n",
    "      activity_matrices.append(np_matrix)\n",
    "    return activity_matrices\n",
    "\n",
    "\n",
    "  def convert(self, path_to_dir):\n",
    "    ids_list = self.__get_unique_ids__()\n",
    "    self.case_logs = self.__get_case_logs__(ids_list)\n",
    "    self.cases_prefix_traces = self.__get_prefix_traces__()\n",
    "\n",
    "    self.activity_matrices = self.__get_activity_matrices__(act_num, act_dict)\n",
    "  \n",
    "    index = 1\n",
    "    for np_matrix in self.activity_matrices:\n",
    "      norm_matrix = np_matrix.copy()\n",
    "      norm_matrix *= 255.0/norm_matrix.max()\n",
    "      A = np.squeeze(np.asarray(norm_matrix)) \n",
    "      img = Image.fromarray(A)\n",
    "\n",
    "      img = img.resize((224, 224), Image.NEAREST)\n",
    "      path = path_to_dir + \"/image_\" + str(index) + \".png\"\n",
    "      index+=1\n",
    "      img.save(path)      \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3d5064-8331-4764-8efb-f0ae6eeb5fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\util\\dt_parsing\\parser.py:76: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|███████████████████████████████████████████| 1000/1000 [00:00<00:00, 1050.27it/s]\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    }
   ],
   "source": [
    "act_conv = ActivityConverter('data_4/Response_Direct.xes', ',', \"concept:instance\", \"concept:name\", \"time:timestamp\")\n",
    "act_conv.convert('data_4/pattern_direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e762b3-16c8-4bda-84d2-235e5e03a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|███████████████████████████████████████████| 1000/1000 [00:00<00:00, 1313.91it/s]\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    }
   ],
   "source": [
    "act_conv = ActivityConverter('data_4/Response_Never.xes', ',', \"concept:instance\", \"concept:name\", \"time:timestamp\")\n",
    "act_conv.convert('data_4/pattern_never')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28d6071-02e6-4d04-91b7-d3ab7241630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|████████████████████████████████████████████| 1000/1000 [00:01<00:00, 845.64it/s]\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    }
   ],
   "source": [
    "act_conv = ActivityConverter('data_4/Existence_Activity_universal.xes', ',', \"concept:instance\", \"concept:name\", \"time:timestamp\")\n",
    "act_conv.convert('data_4/pattern_existence_act_universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28087ae4-bbbf-4f84-a39a-b8346e491f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|████████████████████████████████████████████| 1000/1000 [00:01<00:00, 899.28it/s]\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    }
   ],
   "source": [
    "act_conv = ActivityConverter('data_4/Dependent_Existence_Substitute.xes', ',', \"concept:instance\", \"concept:name\", \"time:timestamp\")\n",
    "act_conv.convert('data_4/pattern_dependent_exst_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5e2d7-cffb-4dbc-97d6-fa362fc6b499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courseproject",
   "language": "python",
   "name": "courseproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
