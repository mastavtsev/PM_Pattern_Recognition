{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c99753-5ccf-4363-9836-327715734a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import pm4py\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db733977-7f3d-4068-b8c4-819dd519724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем уникальные активити\n",
    "activities = ['Start', 'Ist', 'A', 'B', 'Icmp', 'T', 'End', 'C', 'E', 'D']\n",
    "act_dict = {}\n",
    "\n",
    "# проводим  между номером и активити\n",
    "act_num = len(activities)\n",
    "for i in range(act_num):\n",
    "  act_dict[activities[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cdeb27-7533-4bd0-b642-3d19e3218acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Converter(ABC):\n",
    "  \n",
    "  def __init__(self, log_file_path, ch_sep, caseID_col_name, act_col_name, ts_col_name):\n",
    "        # Динамические поля (переменные объекта)\n",
    "        self.caseID_col_name = caseID_col_name \n",
    "        self.act_col_name = act_col_name\n",
    "        self.ts_col_name = ts_col_name\n",
    "\n",
    "        #self.event_log = pd.read_csv(log_file_path, sep=ch_sep)\n",
    "        self.event_log = pm4py.read_xes(log_file_path)\n",
    "        self.event_log[caseID_col_name]=self.event_log[caseID_col_name].apply(str)\n",
    "        self.event_log[act_col_name]=self.event_log[act_col_name].apply(str)\n",
    "        #self.event_log[ts_col_name]= pd.to_datetime(self.event_log[ts_col_name])\n",
    "\n",
    "        self.event_log = self.event_log[[act_col_name, caseID_col_name, ts_col_name]]\n",
    "\n",
    "  @abstractmethod\n",
    "  def convert(self):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c438c7-4cb2-47a3-8fc5-32c5610d4881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ActivityConverter(Converter):\n",
    "\n",
    "  def __get_unique_ids__(self):\n",
    "    ids = list(self.event_log[self.caseID_col_name].unique())\n",
    "    return ids\n",
    "\n",
    "  def __get_case_logs__(self, ids_list):\n",
    "    case_logs = []\n",
    "    for id in ids_list:\n",
    "      case_log = self.event_log.query(\"`{0}` == @id\".format(self.caseID_col_name))\n",
    "      case_log.sort_values(by=[self.ts_col_name])\n",
    "      case_logs.append(case_log)\n",
    "    return case_logs\n",
    "\n",
    "  def __get_prefix_traces__(self):\n",
    "    cases_prefix_traces = []\n",
    "    self.max_len_prefix_trace = 0\n",
    "\n",
    "    for case_log in self.case_logs:\n",
    "      prefix_traces_act = []\n",
    "      for i in range(1, len(case_log)+1):\n",
    "        prifix_trace = case_log[self.act_col_name].values[0:i]\n",
    "\n",
    "        #находим самую длинную префиксную трассу\n",
    "        if (len(prifix_trace) > self.max_len_prefix_trace):\n",
    "          self.max_len_prefix_trace = len(prifix_trace)\n",
    "\n",
    "        prefix_traces_act.append(prifix_trace)\n",
    "\n",
    "      cases_prefix_traces.append(prefix_traces_act)\n",
    "    return cases_prefix_traces\n",
    "\n",
    "  def __get_activity_matrices__(self, act_num, act_dict):\n",
    "    activity_matrices = []\n",
    "    for prefix_traces in self.cases_prefix_traces:\n",
    "      np_matrix = []\n",
    "      matrix = [ [0]*act_num for i in range(self.max_len_prefix_trace)]\n",
    "      for i in range(len(prefix_traces)):\n",
    "        for act in prefix_traces[i]:\n",
    "          act_index = act_dict[act]\n",
    "          matrix[i][act_index] += 1\n",
    "          np_matrix = np.asmatrix(matrix)\n",
    "          np_matrix = np_matrix.astype(\"uint8\")\n",
    "      activity_matrices.append(np_matrix)\n",
    "    return activity_matrices\n",
    "\n",
    "\n",
    "  def convert(self, path_to_dir):\n",
    "    ids_list = self.__get_unique_ids__()\n",
    "    self.case_logs = self.__get_case_logs__(ids_list)\n",
    "    self.cases_prefix_traces = self.__get_prefix_traces__()\n",
    "  \n",
    "    self.activity_matrices = self.__get_activity_matrices__(act_num, act_dict)\n",
    "  \n",
    "    index = 1\n",
    "    for np_matrix in self.activity_matrices:\n",
    "      norm_matrix = np_matrix.copy()\n",
    "      norm_matrix *= 255.0/norm_matrix.max()\n",
    "      A = np.squeeze(np.asarray(norm_matrix)) \n",
    "      img = Image.fromarray(A)\n",
    "\n",
    "      img = img.resize((224, 224), Image.NEAREST)\n",
    "      path = path_to_dir + \"/image_\" + str(index) + \".png\"\n",
    "      index+=1\n",
    "      img.save(path)      \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0807491-fc49-4f2c-95fd-3f4c2884f514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|████████████████████████████████████████████| 1000/1000 [00:03<00:00, 309.54it/s]\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n",
      "D:\\CoureseProject\\ResponseNeverLogClassification\\courseproject\\lib\\site-packages\\pm4py\\objects\\log\\util\\dataframe_utils.py:176: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    }
   ],
   "source": [
    "act_conv = ActivityConverter('data_4/test_net_4_RD_EAU_patterns.xes', ',', \"concept:instance\", \"concept:name\", \"time:timestamp\")\n",
    "\n",
    "act_conv.convert('data_4/Test_net_4_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c016995-e306-40e8-8283-c3a41b7608e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 files belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pattern_dependent_exst_sub',\n",
       " 'pattern_direct',\n",
       " 'pattern_existence_act_universal',\n",
       " 'pattern_never']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = tf.keras.utils.image_dataset_from_directory('data_4/patterns').class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f121593-1e53-4e09-9761-768b3bdb9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('models','pattern_model_4.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440902dc-1288-4c22-a987-b6f36effcc18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "files = glob.glob(\"data_4/Test_net_4_images/*.png\")\n",
    "for myFile in files:\n",
    "    image = cv2.imread(myFile)\n",
    "    resize = tf.image.resize(image, (256,256))\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "    classes.append(class_names[np.argmax(yhat)])\n",
    "# for img in data:\n",
    "#     resize = tf.image.resize(img, (256,256))\n",
    "#     yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "#     classes.append(class_names[np.argmax(yhat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db177a19-d554-491f-ac11-41d50eca39f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pattern_dependent_exst_sub', 'pattern_direct'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da459e95-bcbf-475a-ac71-e39ec7bc3adb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courseproject",
   "language": "python",
   "name": "courseproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
